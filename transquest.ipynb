{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "transquest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haleyrx/qe_project/blob/main/transquest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPkGlI90jLv8"
      },
      "source": [
        "## **Prep**"
      ],
      "id": "EPkGlI90jLv8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DgvOrJpMzT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fffe33-8e77-473d-ae06-95cf881ad25c"
      },
      "source": [
        "! git clone https://2726c3be06d254f6092d9413236205338399aed0@github.com/haleyrx/qe_project"
      ],
      "id": "1DgvOrJpMzT8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'qe_project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10Fg1qM1NOnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d81349-80aa-480e-e85e-5b63fe1008f8"
      },
      "source": [
        "!pip install sentencepiece\n",
        "! pip install transformers\n"
      ],
      "id": "10Fg1qM1NOnI",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2QTWHwjN8Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378dc18b-3bfc-4a7a-b124-9945f2ec50d9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "B2QTWHwjN8Lp",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr  8 15:46:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE3G-EhYn5Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff799bb-5ff9-416d-d20b-70b9b682731f"
      },
      "source": [
        "%cd qe_project"
      ],
      "id": "LE3G-EhYn5Pu",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/qe_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiL9PxhpjSkS"
      },
      "source": [
        "## Read in Data"
      ],
      "id": "HiL9PxhpjSkS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQW0bZbMmrac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0627dc20-392f-4a92-c057-fc2be7810b7e"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('./data/en-de/train.ende.df.short.tsv',sep=\"\\t\")\n",
        "train = df_train[['original', 'translation', 'z_mean']]\n",
        "train.head()"
      ],
      "id": "IQW0bZbMmrac",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
              "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
              "      <td>1.119409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>However, a disappointing ninth in China meant ...</td>\n",
              "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
              "      <td>-0.488591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In his diary, Chase wrote that the release of ...</td>\n",
              "      <td>In seinem Tagebuch, Chase schrieb, dass die Ve...</td>\n",
              "      <td>-2.207007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
              "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
              "      <td>-0.799946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Once North Pacific salmon die off after spawni...</td>\n",
              "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
              "      <td>0.381633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  José Ortega y Gasset visited Husserl at Freibu...  ...  1.119409\n",
              "1  However, a disappointing ninth in China meant ...  ... -0.488591\n",
              "2  In his diary, Chase wrote that the release of ...  ... -2.207007\n",
              "3  Heavy arquebuses mounted on wagons were called...  ... -0.799946\n",
              "4  Once North Pacific salmon die off after spawni...  ...  0.381633\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fPn0pdAv94XL",
        "outputId": "f78bba49-10a1-4d18-c018-4918ceaa2583"
      },
      "source": [
        "df_dev = pd.read_csv('./data/en-de/dev.ende.df.short.tsv',sep='\\t')\n",
        "dev = df_dev[['original', 'translation', 'z_mean']]\n",
        "dev.head()"
      ],
      "id": "fPn0pdAv94XL",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simultaneously, the Legion took part to the pa...</td>\n",
              "      <td>Gleichzeitig nahm die Legion an der Befriedung...</td>\n",
              "      <td>-0.312186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He also begins an affair with Veronica Harring...</td>\n",
              "      <td>Er beginnt auch eine Affäre mit Veronica Harri...</td>\n",
              "      <td>-0.401581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The urban morphology of these two local waters...</td>\n",
              "      <td>Die urbane Morphologie dieser beiden lokalen W...</td>\n",
              "      <td>0.275414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Important finds included a bronze axe in Wellw...</td>\n",
              "      <td>Wichtige Funde waren eine Bronzeaxt in Wellwoo...</td>\n",
              "      <td>0.580925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Previously, Englishmen had drunk mainly dark s...</td>\n",
              "      <td>Früher hatten Engländer vor allem dunkle Stout...</td>\n",
              "      <td>-1.895129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  Simultaneously, the Legion took part to the pa...  ... -0.312186\n",
              "1  He also begins an affair with Veronica Harring...  ... -0.401581\n",
              "2  The urban morphology of these two local waters...  ...  0.275414\n",
              "3  Important finds included a bronze axe in Wellw...  ...  0.580925\n",
              "4  Previously, Englishmen had drunk mainly dark s...  ... -1.895129\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G19rmEtc-It0",
        "outputId": "638e72c5-febc-405a-e988-066306805feb"
      },
      "source": [
        "df_test = pd.read_csv('./data/en-de/test20.ende.df.short.tsv',sep='\\t')\n",
        "test = df_test[['original', 'translation', 'z_mean']]\n",
        "test.head()"
      ],
      "id": "G19rmEtc-It0",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Sultan appoints judges, and can grant pard...</td>\n",
              "      <td>Der Sultan ernennt Richter und kann Begnadigun...</td>\n",
              "      <td>0.349371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Antisemitism in modern Ukraine Antisemitism an...</td>\n",
              "      <td>Antisemitismus in der modernen Ukraine Antisem...</td>\n",
              "      <td>0.392435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morales continued his feud with Buddy Rose, de...</td>\n",
              "      <td>Morales setzte seine Fehde mit Buddy Rose fort...</td>\n",
              "      <td>0.645034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>American Maury Tripp attended the Jamboree fro...</td>\n",
              "      <td>Der Amerikaner Maury Tripp besuchte das Jambor...</td>\n",
              "      <td>0.544519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He bowled a series of bouncers at Viv Richards...</td>\n",
              "      <td>Er boomte eine Reihe von Bouncern bei Viv Rich...</td>\n",
              "      <td>-0.589531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  The Sultan appoints judges, and can grant pard...  ...  0.349371\n",
              "1  Antisemitism in modern Ukraine Antisemitism an...  ...  0.392435\n",
              "2  Morales continued his feud with Buddy Rose, de...  ...  0.645034\n",
              "3  American Maury Tripp attended the Jamboree fro...  ...  0.544519\n",
              "4  He bowled a series of bouncers at Viv Richards...  ... -0.589531\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbrap085-aMC"
      },
      "source": [
        "index = df_test['index'].to_list()"
      ],
      "id": "bbrap085-aMC",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwDjf70J-lMB"
      },
      "source": [
        "train = train.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()\n",
        "dev = dev.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()\n",
        "test = test.rename(columns={'original': 'text_a', 'translation': 'text_b'}).dropna()"
      ],
      "id": "AwDjf70J-lMB",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "searching-equity"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "\n",
        "def fit(df, label):\n",
        "    x = df[[label]].values.astype(float)\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "    df[label] = x_scaled\n",
        "    return df\n",
        "\n",
        "\n",
        "def un_fit(df, label):\n",
        "    x = df[[label]].values.astype(float)\n",
        "    x_unscaled = min_max_scaler.inverse_transform(x)\n",
        "    df[label] = x_unscaled\n",
        "    return df"
      ],
      "id": "searching-equity",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcLQXavR_iY_"
      },
      "source": [
        "test_sentence_pairs = list(map(list, zip(test['text_a'].to_list(), test['text_b'].to_list())))\n",
        "\n",
        "train = fit(train, 'labels')\n",
        "dev = fit(dev, 'labels')"
      ],
      "id": "rcLQXavR_iY_",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vSsgptt_vEe"
      },
      "source": [
        "# Model parameters\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "SEED = 777\n",
        "TEMP_DIRECTORY = \"temp/data\"\n",
        "RESULT_FILE = \"result.tsv\"\n",
        "SUBMISSION_FILE = \"predictions.txt\"\n",
        "RESULT_IMAGE = \"result.jpg\"\n",
        "GOOGLE_DRIVE = False\n",
        "DRIVE_FILE_ID = None\n",
        "MODEL_TYPE = \"xlmroberta\"\n",
        "MODEL_NAME = \"xlm-roberta-large\"\n",
        "\n",
        "monotransquest_config = {\n",
        "    'output_dir': 'temp/outputs/',\n",
        "    \"best_model_dir\": \"temp/outputs/best_model\",\n",
        "    'cache_dir': 'temp/cache_dir/',\n",
        "\n",
        "    'fp16': False,\n",
        "    'fp16_opt_level': 'O1',\n",
        "    'max_seq_length': 128,\n",
        "    'train_batch_size': 8,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'eval_batch_size': 8,\n",
        "    'num_train_epochs': 3,\n",
        "    'weight_decay': 0,\n",
        "    'learning_rate': 1e-5,\n",
        "    'adam_epsilon': 1e-8,\n",
        "    'warmup_ratio': 0.1,\n",
        "    'warmup_steps': 0,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'do_lower_case': False,\n",
        "\n",
        "    'logging_steps': 300,\n",
        "    'save_steps': 300,\n",
        "    \"no_cache\": False,\n",
        "    \"no_save\": False,\n",
        "    \"save_recent_only\": True,\n",
        "    'save_model_every_epoch': False,\n",
        "    'n_fold': 3,\n",
        "    'evaluate_during_training': True,\n",
        "    \"evaluate_during_training_silent\": True,\n",
        "    'evaluate_during_training_steps': 300,\n",
        "    \"evaluate_during_training_verbose\": True,\n",
        "    'use_cached_eval_features': False,\n",
        "    \"save_best_model\": True,\n",
        "    'save_eval_checkpoints': True,\n",
        "    'tensorboard_dir': None,\n",
        "    \"save_optimizer_and_scheduler\": True,\n",
        "\n",
        "    'regression': True,\n",
        "\n",
        "    'overwrite_output_dir': True,\n",
        "    'reprocess_input_data': True,\n",
        "\n",
        "    'process_count': cpu_count() - 2 if cpu_count() > 2 else 1,\n",
        "    'n_gpu': 1,\n",
        "    'use_multiprocessing': True,\n",
        "    \"multiprocessing_chunksize\": 500,\n",
        "    'silent': False,\n",
        "\n",
        "    'wandb_project': None,\n",
        "    'wandb_kwargs': {},\n",
        "\n",
        "    \"use_early_stopping\": True,\n",
        "    \"early_stopping_patience\": 10,\n",
        "    \"early_stopping_delta\": 0,\n",
        "    \"early_stopping_metric\": \"eval_loss\",\n",
        "    \"early_stopping_metric_minimize\": True,\n",
        "    \"early_stopping_consider_epochs\": False,\n",
        "\n",
        "    \"manual_seed\": SEED,\n",
        "\n",
        "    \"config\": {},\n",
        "    \"local_rank\": -1,\n",
        "    \"encoding\": None,\n",
        "}"
      ],
      "id": "6vSsgptt_vEe",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "vO8MagGZHOvD",
        "outputId": "3b7f289a-bca3-4992-88f1-a0743930acca"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "outputs = model(**inputs, labels=labels)\n",
        "loss = outputs.loss\n",
        "logits = outputs.logits"
      ],
      "id": "vO8MagGZHOvD",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a001e10bf7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xlm-roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello, my dog is cute\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Batch size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MQNuL1ZHrTE",
        "outputId": "1e19a19c-2a89-4ed9-f14b-9806e196451a"
      },
      "source": [
        "loss"
      ],
      "id": "0MQNuL1ZHrTE",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7190, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fWXgvWcHs4C",
        "outputId": "4f6fa83a-d960-44a2-fc71-45dc6e6707ce"
      },
      "source": [
        "logits"
      ],
      "id": "8fWXgvWcHs4C",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1105, 0.0595]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "xfHrwL-mAPgX",
        "outputId": "6944255c-be4c-4ab2-e78f-c5097447fd67"
      },
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## PyTorch Transformer\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig"
      ],
      "id": "xfHrwL-mAPgX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cee6798a803f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m## PyTorch Transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobertaModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkIwLcbhEa_N"
      },
      "source": [
        ""
      ],
      "id": "PkIwLcbhEa_N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn5LtG3tMhFA"
      },
      "source": [
        "# New Section"
      ],
      "id": "Dn5LtG3tMhFA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unknown-convenience",
        "outputId": "011048e3-fe59-4e01-cae6-08d047fd72dc"
      },
      "source": [
        "class RobertaForSequenceClassification(RobertaPreTrainedModel):\n",
        "    config_class = RobertaConfig\n",
        "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
        "    base_model_prefix = \"roberta\"\n",
        "    \n",
        "     def __init__(self, config, weight=None):\n",
        "        super(RobertaForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.classifier = RobertaClassificationHead(config)\n",
        "        self.weight = weight\n",
        "    \n",
        "     def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "            outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.classifier(sequence_output)\n",
        "        \n",
        "        #outputs = (logits,) + outputs[2:]\n",
        "        \n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        output = (logits,) + outputs[2:]\n",
        "        return ((loss,) + output) if loss is not None else output"
      ],
      "id": "unknown-convenience",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-7-e5c9ed129cf5>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e5c9ed129cf5>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    def __init__(self, config, weight=None):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iraqi-dylan"
      },
      "source": [
        ""
      ],
      "id": "iraqi-dylan",
      "execution_count": null,
      "outputs": []
    }
  ]
}