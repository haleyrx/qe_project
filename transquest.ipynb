{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "transquest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haleyrx/qe_project/blob/main/transquest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPkGlI90jLv8"
      },
      "source": [
        "## **Prep**"
      ],
      "id": "EPkGlI90jLv8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DgvOrJpMzT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaedc8a-931f-4846-966c-79d43775773b"
      },
      "source": [
        "! git clone https://2726c3be06d254f6092d9413236205338399aed0@github.com/haleyrx/qe_project"
      ],
      "id": "1DgvOrJpMzT8",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'qe_project'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 30 (delta 4), reused 26 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10Fg1qM1NOnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d9aca1-0285-4cd3-d175-121731f7cfb1"
      },
      "source": [
        "! pip install transformers"
      ],
      "id": "10Fg1qM1NOnI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=3f1a3231a3b44698f24e5bfaf67eec7337378c55ee31f86b1042f751140daae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2QTWHwjN8Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8217b99-1c28-4e37-fd67-fe1f0e970c07"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "B2QTWHwjN8Lp",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr  8 14:49:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE3G-EhYn5Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff799bb-5ff9-416d-d20b-70b9b682731f"
      },
      "source": [
        "%cd qe_project"
      ],
      "id": "LE3G-EhYn5Pu",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/qe_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiL9PxhpjSkS"
      },
      "source": [
        "## Read in Data"
      ],
      "id": "HiL9PxhpjSkS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQW0bZbMmrac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0627dc20-392f-4a92-c057-fc2be7810b7e"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('./data/en-de/train.ende.df.short.tsv',sep=\"\\t\")\n",
        "train = df_train[['original', 'translation', 'z_mean']]\n",
        "train.head()"
      ],
      "id": "IQW0bZbMmrac",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
              "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
              "      <td>1.119409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>However, a disappointing ninth in China meant ...</td>\n",
              "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
              "      <td>-0.488591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In his diary, Chase wrote that the release of ...</td>\n",
              "      <td>In seinem Tagebuch, Chase schrieb, dass die Ve...</td>\n",
              "      <td>-2.207007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
              "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
              "      <td>-0.799946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Once North Pacific salmon die off after spawni...</td>\n",
              "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
              "      <td>0.381633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  José Ortega y Gasset visited Husserl at Freibu...  ...  1.119409\n",
              "1  However, a disappointing ninth in China meant ...  ... -0.488591\n",
              "2  In his diary, Chase wrote that the release of ...  ... -2.207007\n",
              "3  Heavy arquebuses mounted on wagons were called...  ... -0.799946\n",
              "4  Once North Pacific salmon die off after spawni...  ...  0.381633\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fPn0pdAv94XL",
        "outputId": "f78bba49-10a1-4d18-c018-4918ceaa2583"
      },
      "source": [
        "df_dev = pd.read_csv('./data/en-de/dev.ende.df.short.tsv',sep='\\t')\n",
        "dev = df_dev[['original', 'translation', 'z_mean']]\n",
        "dev.head()"
      ],
      "id": "fPn0pdAv94XL",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simultaneously, the Legion took part to the pa...</td>\n",
              "      <td>Gleichzeitig nahm die Legion an der Befriedung...</td>\n",
              "      <td>-0.312186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He also begins an affair with Veronica Harring...</td>\n",
              "      <td>Er beginnt auch eine Affäre mit Veronica Harri...</td>\n",
              "      <td>-0.401581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The urban morphology of these two local waters...</td>\n",
              "      <td>Die urbane Morphologie dieser beiden lokalen W...</td>\n",
              "      <td>0.275414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Important finds included a bronze axe in Wellw...</td>\n",
              "      <td>Wichtige Funde waren eine Bronzeaxt in Wellwoo...</td>\n",
              "      <td>0.580925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Previously, Englishmen had drunk mainly dark s...</td>\n",
              "      <td>Früher hatten Engländer vor allem dunkle Stout...</td>\n",
              "      <td>-1.895129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  Simultaneously, the Legion took part to the pa...  ... -0.312186\n",
              "1  He also begins an affair with Veronica Harring...  ... -0.401581\n",
              "2  The urban morphology of these two local waters...  ...  0.275414\n",
              "3  Important finds included a bronze axe in Wellw...  ...  0.580925\n",
              "4  Previously, Englishmen had drunk mainly dark s...  ... -1.895129\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G19rmEtc-It0",
        "outputId": "638e72c5-febc-405a-e988-066306805feb"
      },
      "source": [
        "df_test = pd.read_csv('./data/en-de/test20.ende.df.short.tsv',sep='\\t')\n",
        "test = df_test[['original', 'translation', 'z_mean']]\n",
        "test.head()"
      ],
      "id": "G19rmEtc-It0",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Sultan appoints judges, and can grant pard...</td>\n",
              "      <td>Der Sultan ernennt Richter und kann Begnadigun...</td>\n",
              "      <td>0.349371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Antisemitism in modern Ukraine Antisemitism an...</td>\n",
              "      <td>Antisemitismus in der modernen Ukraine Antisem...</td>\n",
              "      <td>0.392435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morales continued his feud with Buddy Rose, de...</td>\n",
              "      <td>Morales setzte seine Fehde mit Buddy Rose fort...</td>\n",
              "      <td>0.645034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>American Maury Tripp attended the Jamboree fro...</td>\n",
              "      <td>Der Amerikaner Maury Tripp besuchte das Jambor...</td>\n",
              "      <td>0.544519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He bowled a series of bouncers at Viv Richards...</td>\n",
              "      <td>Er boomte eine Reihe von Bouncern bei Viv Rich...</td>\n",
              "      <td>-0.589531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  The Sultan appoints judges, and can grant pard...  ...  0.349371\n",
              "1  Antisemitism in modern Ukraine Antisemitism an...  ...  0.392435\n",
              "2  Morales continued his feud with Buddy Rose, de...  ...  0.645034\n",
              "3  American Maury Tripp attended the Jamboree fro...  ...  0.544519\n",
              "4  He bowled a series of bouncers at Viv Richards...  ... -0.589531\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbrap085-aMC"
      },
      "source": [
        "index = df_test['index'].to_list()"
      ],
      "id": "bbrap085-aMC",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwDjf70J-lMB"
      },
      "source": [
        "train = train.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()\n",
        "dev = dev.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()\n",
        "test = test.rename(columns={'original': 'text_a', 'translation': 'text_b'}).dropna()"
      ],
      "id": "AwDjf70J-lMB",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "searching-equity"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "\n",
        "def fit(df, label):\n",
        "    x = df[[label]].values.astype(float)\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "    df[label] = x_scaled\n",
        "    return df\n",
        "\n",
        "\n",
        "def un_fit(df, label):\n",
        "    x = df[[label]].values.astype(float)\n",
        "    x_unscaled = min_max_scaler.inverse_transform(x)\n",
        "    df[label] = x_unscaled\n",
        "    return df"
      ],
      "id": "searching-equity",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcLQXavR_iY_"
      },
      "source": [
        "test_sentence_pairs = list(map(list, zip(test['text_a'].to_list(), test['text_b'].to_list())))\n",
        "\n",
        "train = fit(train, 'labels')\n",
        "dev = fit(dev, 'labels')"
      ],
      "id": "rcLQXavR_iY_",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vSsgptt_vEe"
      },
      "source": [
        "# Model parameters\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "SEED = 777\n",
        "TEMP_DIRECTORY = \"temp/data\"\n",
        "RESULT_FILE = \"result.tsv\"\n",
        "SUBMISSION_FILE = \"predictions.txt\"\n",
        "RESULT_IMAGE = \"result.jpg\"\n",
        "GOOGLE_DRIVE = False\n",
        "DRIVE_FILE_ID = None\n",
        "MODEL_TYPE = \"xlmroberta\"\n",
        "MODEL_NAME = \"xlm-roberta-large\"\n",
        "\n",
        "monotransquest_config = {\n",
        "    'output_dir': 'temp/outputs/',\n",
        "    \"best_model_dir\": \"temp/outputs/best_model\",\n",
        "    'cache_dir': 'temp/cache_dir/',\n",
        "\n",
        "    'fp16': False,\n",
        "    'fp16_opt_level': 'O1',\n",
        "    'max_seq_length': 128,\n",
        "    'train_batch_size': 8,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'eval_batch_size': 8,\n",
        "    'num_train_epochs': 3,\n",
        "    'weight_decay': 0,\n",
        "    'learning_rate': 1e-5,\n",
        "    'adam_epsilon': 1e-8,\n",
        "    'warmup_ratio': 0.1,\n",
        "    'warmup_steps': 0,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'do_lower_case': False,\n",
        "\n",
        "    'logging_steps': 300,\n",
        "    'save_steps': 300,\n",
        "    \"no_cache\": False,\n",
        "    \"no_save\": False,\n",
        "    \"save_recent_only\": True,\n",
        "    'save_model_every_epoch': False,\n",
        "    'n_fold': 3,\n",
        "    'evaluate_during_training': True,\n",
        "    \"evaluate_during_training_silent\": True,\n",
        "    'evaluate_during_training_steps': 300,\n",
        "    \"evaluate_during_training_verbose\": True,\n",
        "    'use_cached_eval_features': False,\n",
        "    \"save_best_model\": True,\n",
        "    'save_eval_checkpoints': True,\n",
        "    'tensorboard_dir': None,\n",
        "    \"save_optimizer_and_scheduler\": True,\n",
        "\n",
        "    'regression': True,\n",
        "\n",
        "    'overwrite_output_dir': True,\n",
        "    'reprocess_input_data': True,\n",
        "\n",
        "    'process_count': cpu_count() - 2 if cpu_count() > 2 else 1,\n",
        "    'n_gpu': 1,\n",
        "    'use_multiprocessing': True,\n",
        "    \"multiprocessing_chunksize\": 500,\n",
        "    'silent': False,\n",
        "\n",
        "    'wandb_project': None,\n",
        "    'wandb_kwargs': {},\n",
        "\n",
        "    \"use_early_stopping\": True,\n",
        "    \"early_stopping_patience\": 10,\n",
        "    \"early_stopping_delta\": 0,\n",
        "    \"early_stopping_metric\": \"eval_loss\",\n",
        "    \"early_stopping_metric_minimize\": True,\n",
        "    \"early_stopping_consider_epochs\": False,\n",
        "\n",
        "    \"manual_seed\": SEED,\n",
        "\n",
        "    \"config\": {},\n",
        "    \"local_rank\": -1,\n",
        "    \"encoding\": None,\n",
        "}"
      ],
      "id": "6vSsgptt_vEe",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfHrwL-mAPgX"
      },
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "xfHrwL-mAPgX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn5LtG3tMhFA"
      },
      "source": [
        "# New Section"
      ],
      "id": "Dn5LtG3tMhFA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unknown-convenience",
        "outputId": "011048e3-fe59-4e01-cae6-08d047fd72dc"
      },
      "source": [
        "class RobertaForSequenceClassification(RobertaPreTrainedModel):\n",
        "    config_class = RobertaConfig\n",
        "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
        "    base_model_prefix = \"roberta\"\n",
        "    \n",
        "     def __init__(self, config, weight=None):\n",
        "        super(RobertaForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.classifier = RobertaClassificationHead(config)\n",
        "        self.weight = weight\n",
        "    \n",
        "     def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "            outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.classifier(sequence_output)\n",
        "        \n",
        "        #outputs = (logits,) + outputs[2:]\n",
        "        \n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        output = (logits,) + outputs[2:]\n",
        "        return ((loss,) + output) if loss is not None else output"
      ],
      "id": "unknown-convenience",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-7-e5c9ed129cf5>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e5c9ed129cf5>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    def __init__(self, config, weight=None):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iraqi-dylan"
      },
      "source": [
        ""
      ],
      "id": "iraqi-dylan",
      "execution_count": null,
      "outputs": []
    }
  ]
}