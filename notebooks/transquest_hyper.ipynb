{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "transquest_hyper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haleyrx/qe_project/blob/main/transquest_hyper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPkGlI90jLv8"
      },
      "source": [
        "## **Prep**"
      ],
      "id": "EPkGlI90jLv8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v8uSC_O3y3P",
        "outputId": "38daa795-8031-45ed-e8a8-19865476529a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "_v8uSC_O3y3P",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq8KdSHZ33KE",
        "outputId": "02cc608e-c6d8-4f5b-b708-a7ef275fe0c3"
      },
      "source": [
        "%cd gdrive/MyDrive/CS7643"
      ],
      "id": "Dq8KdSHZ33KE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/CS7643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gvf0FETZUU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c70bc1a-9852-44dc-dffb-208a20e8e9cc"
      },
      "source": [
        "! git clone https://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@github.com/haleyrx/qe_project.git"
      ],
      "id": "_gvf0FETZUU1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'qe_project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orqmv_FO4UKR",
        "outputId": "9020a48d-0fd6-4853-ee95-f6b75eb59f7f"
      },
      "source": [
        "!ls"
      ],
      "id": "Orqmv_FO4UKR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colab_setup.ipynb  CS7643_HW4  qe_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SPIeCW5391t",
        "outputId": "49b896c1-676d-4bda-9389-633d88cce44b"
      },
      "source": [
        "%cd qe_project\n",
        "# ! git pull https://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@github.com/haleyrx/qe_project.git"
      ],
      "id": "8SPIeCW5391t",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/CS7643/qe_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9X_3r0hZ25w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d0fc6c-2f77-4177-8063-76a307445d7a"
      },
      "source": [
        "!pwd"
      ],
      "id": "D9X_3r0hZ25w",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/CS7643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxaU4bgoRM9n"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/CS7643/qe_project/code')"
      ],
      "id": "JxaU4bgoRM9n",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10Fg1qM1NOnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d205a467-23de-4444-f39f-a4f31fc100ff"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers==3.0.2"
      ],
      "id": "10Fg1qM1NOnI",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 30.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 21.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 17.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 14.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 14.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 14.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 14.2MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 14.2MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 14.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 20.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.95)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2QTWHwjN8Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1490b3-c076-418a-dad0-b6c2bccb155b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "B2QTWHwjN8Lp",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 26 01:38:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE3G-EhYn5Pu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4df0704-abec-4cb1-9445-ec770bfd103b"
      },
      "source": [
        "%pwd"
      ],
      "id": "LE3G-EhYn5Pu",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/CS7643/qe_project'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFMB3O7ZtxF-"
      },
      "source": [
        "### Set parameters"
      ],
      "id": "DFMB3O7ZtxF-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vSsgptt_vEe"
      },
      "source": [
        "SEED = 0\n",
        "RESULT_FILE = 'en-de_result.tsv'\n",
        "METRICS_FILE = 'en-de_metrics.txt'\n",
        "BEST_MODEL_FILE = 'en-de_best_model.bin'\n",
        "MODEL_TYPE = 'xlmroberta'\n",
        "MODEL_NAME = 'xlm-roberta-large'\n",
        "TRAIN_DATA = 'en-de/train.ende.df.short.tsv'\n",
        "DEV_DATA = 'en-de/dev.ende.df.short.tsv'\n",
        "TEST_DATA = 'en-de/test20.ende.df.short.tsv'\n",
        "DATA_DIR = './data/'\n",
        "OUTPUT_DIR = './results/'\n",
        "BEST_MODEL_DIR = './best_models/'\n",
        "\n",
        "# Model parameters\n",
        "args = {\n",
        "    'max_seq_length': 128,\n",
        "    'train_batch_size': 8,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'eval_batch_size': 8,\n",
        "    'num_train_epochs': 3,\n",
        "    'weight_decay': 0,\n",
        "    'learning_rate': 1e-5,\n",
        "    'adam_epsilon': 1e-8,\n",
        "    'warmup_ratio': 0.1,\n",
        "    'warmup_steps': 0,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'dropout': 0.2\n",
        "}"
      ],
      "id": "6vSsgptt_vEe",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7w7rmTrTcjv"
      },
      "source": [
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import XLMRobertaConfig, XLMRobertaTokenizer, XLMRobertaModel\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy import stats\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import math"
      ],
      "id": "J7w7rmTrTcjv",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYnB2vQpuAfR"
      },
      "source": [
        "import os\n",
        "# Get relevant paths\n",
        "train_path = os.path.join(DATA_DIR, TRAIN_DATA)\n",
        "dev_path = os.path.join(DATA_DIR, DEV_DATA)\n",
        "test_path = os.path.join(DATA_DIR, TEST_DATA)\n",
        "results_path = os.path.join(OUTPUT_DIR, RESULT_FILE)"
      ],
      "id": "YYnB2vQpuAfR",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BoQbUi9lrPph",
        "outputId": "ab8e3078-6868-4e9e-db75-1f7aa64ef465"
      },
      "source": [
        "train_path"
      ],
      "id": "BoQbUi9lrPph",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data/en-de/train.ende.df.short.tsv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiL9PxhpjSkS"
      },
      "source": [
        "## Read in Data"
      ],
      "id": "HiL9PxhpjSkS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoauqED0Drop"
      },
      "source": [
        "from utils import read_file, fit, un_fit, get_metrics"
      ],
      "id": "UoauqED0Drop",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQW0bZbMmrac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "feafcda4-40cf-4223-c662-d22a6ffbe36e"
      },
      "source": [
        "df_train = read_file(train_path)\n",
        "train = df_train[['original', 'translation', 'z_mean']]\n",
        "train.head()"
      ],
      "id": "IQW0bZbMmrac",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
              "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
              "      <td>1.119409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>However, a disappointing ninth in China meant ...</td>\n",
              "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
              "      <td>-0.488591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In his diary, Chase wrote that the release of ...</td>\n",
              "      <td>In seinem Tagebuch, Chase schrieb, dass die Ve...</td>\n",
              "      <td>-2.207007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
              "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
              "      <td>-0.799946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Once North Pacific salmon die off after spawni...</td>\n",
              "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
              "      <td>0.381633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  José Ortega y Gasset visited Husserl at Freibu...  ...  1.119409\n",
              "1  However, a disappointing ninth in China meant ...  ... -0.488591\n",
              "2  In his diary, Chase wrote that the release of ...  ... -2.207007\n",
              "3  Heavy arquebuses mounted on wagons were called...  ... -0.799946\n",
              "4  Once North Pacific salmon die off after spawni...  ...  0.381633\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fPn0pdAv94XL",
        "outputId": "6a28de35-6b74-476c-f990-2e86d7318c0c"
      },
      "source": [
        "df_dev = read_file(dev_path)\n",
        "dev = df_dev[['original', 'translation', 'z_mean']]\n",
        "dev.head()"
      ],
      "id": "fPn0pdAv94XL",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simultaneously, the Legion took part to the pa...</td>\n",
              "      <td>Gleichzeitig nahm die Legion an der Befriedung...</td>\n",
              "      <td>-0.312186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He also begins an affair with Veronica Harring...</td>\n",
              "      <td>Er beginnt auch eine Affäre mit Veronica Harri...</td>\n",
              "      <td>-0.401581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The urban morphology of these two local waters...</td>\n",
              "      <td>Die urbane Morphologie dieser beiden lokalen W...</td>\n",
              "      <td>0.275414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Important finds included a bronze axe in Wellw...</td>\n",
              "      <td>Wichtige Funde waren eine Bronzeaxt in Wellwoo...</td>\n",
              "      <td>0.580925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Previously, Englishmen had drunk mainly dark s...</td>\n",
              "      <td>Früher hatten Engländer vor allem dunkle Stout...</td>\n",
              "      <td>-1.895129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  Simultaneously, the Legion took part to the pa...  ... -0.312186\n",
              "1  He also begins an affair with Veronica Harring...  ... -0.401581\n",
              "2  The urban morphology of these two local waters...  ...  0.275414\n",
              "3  Important finds included a bronze axe in Wellw...  ...  0.580925\n",
              "4  Previously, Englishmen had drunk mainly dark s...  ... -1.895129\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G19rmEtc-It0",
        "outputId": "cdd6434c-8364-4fb8-d3b1-0d869cb44764"
      },
      "source": [
        "df_test = read_file(test_path)\n",
        "test = df_test[['original', 'translation', 'z_mean']]\n",
        "test.head()"
      ],
      "id": "G19rmEtc-It0",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Sultan appoints judges, and can grant pard...</td>\n",
              "      <td>Der Sultan ernennt Richter und kann Begnadigun...</td>\n",
              "      <td>0.349371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Antisemitism in modern Ukraine Antisemitism an...</td>\n",
              "      <td>Antisemitismus in der modernen Ukraine Antisem...</td>\n",
              "      <td>0.392435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morales continued his feud with Buddy Rose, de...</td>\n",
              "      <td>Morales setzte seine Fehde mit Buddy Rose fort...</td>\n",
              "      <td>0.645034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>American Maury Tripp attended the Jamboree fro...</td>\n",
              "      <td>Der Amerikaner Maury Tripp besuchte das Jambor...</td>\n",
              "      <td>0.544519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He bowled a series of bouncers at Viv Richards...</td>\n",
              "      <td>Er boomte eine Reihe von Bouncern bei Viv Rich...</td>\n",
              "      <td>-0.589531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...    z_mean\n",
              "0  The Sultan appoints judges, and can grant pard...  ...  0.349371\n",
              "1  Antisemitism in modern Ukraine Antisemitism an...  ...  0.392435\n",
              "2  Morales continued his feud with Buddy Rose, de...  ...  0.645034\n",
              "3  American Maury Tripp attended the Jamboree fro...  ...  0.544519\n",
              "4  He bowled a series of bouncers at Viv Richards...  ... -0.589531\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwDjf70J-lMB"
      },
      "source": [
        "train = train.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()\n",
        "dev = dev.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()\n",
        "test = test.rename(columns={'original': 'text_a', 'translation': 'text_b', 'z_mean': 'labels'}).dropna()"
      ],
      "id": "AwDjf70J-lMB",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcLQXavR_iY_"
      },
      "source": [
        "train = fit(train, 'labels')\n",
        "dev = fit(dev, 'labels')"
      ],
      "id": "rcLQXavR_iY_",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3rD10Qvwt6s"
      },
      "source": [
        "### Create data loader and load batches"
      ],
      "id": "n3rD10Qvwt6s"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGNNC5auM2AN"
      },
      "source": [
        "class TranslationDataset(Dataset):\n",
        "  def __init__(self, text_a, text_b, labels, tokenizer, max_len):\n",
        "    self.text_a = text_a\n",
        "    self.text_b = text_b\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text_a)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    original = str(self.text_a[item])\n",
        "    translation = str(self.text_b[item])\n",
        "    label = float(self.labels[item])\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      original,\n",
        "      translation,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      truncation='longest_first',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'original_text': original,\n",
        "      'translation_text': translation,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'label': torch.tensor(label, dtype=torch.float32)\n",
        "    }"
      ],
      "id": "wGNNC5auM2AN",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5aGo74Il9ci"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = TranslationDataset(\n",
        "    text_a=df.text_a.to_numpy(),\n",
        "    text_b=df.text_b.to_numpy(),\n",
        "    labels=df.labels.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )"
      ],
      "id": "p5aGo74Il9ci",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50emkbPkUPnf"
      },
      "source": [
        "# Initialize config, tokenizer, and pretrained model\n",
        "MODEL_CLASSES = {'xlmroberta': (XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer)}\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[MODEL_TYPE]\n",
        "tokenizer = tokenizer_class.from_pretrained(MODEL_NAME)"
      ],
      "id": "50emkbPkUPnf",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mgdstvfmxlv"
      },
      "source": [
        "train_data_loader = create_data_loader(train, tokenizer, args['max_seq_length'], args['train_batch_size'])\n",
        "dev_data_loader = create_data_loader(dev, tokenizer, args['max_seq_length'], args['train_batch_size'])\n",
        "test_data_loader = create_data_loader(test, tokenizer, args['max_seq_length'], args['train_batch_size'])"
      ],
      "id": "6mgdstvfmxlv",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpy69dtawS34"
      },
      "source": [
        "### Import packages"
      ],
      "id": "Xpy69dtawS34"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCiPHSh-TYta",
        "outputId": "c3dca46f-8ae8-44a1-a5d3-61ed6e7c6dc3"
      },
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "MCiPHSh-TYta",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgSEt44wp6p"
      },
      "source": [
        "### Download pretrained model"
      ],
      "id": "zmgSEt44wp6p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg_V0Zhhw6Ll"
      },
      "source": [
        "### Define MonoTransQuest Model"
      ],
      "id": "hg_V0Zhhw6Ll"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IElDL0WPuyK9"
      },
      "source": [
        "class MonoTransQuest(nn.Module):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super(MonoTransQuest, self).__init__()\n",
        "    self.model = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n",
        "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    sequence_output = outputs[0]\n",
        "    x = sequence_output[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
        "    x = self.dropout(x)\n",
        "    x = self.dense(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.out_proj(x)\n",
        "\n",
        "    return torch.sigmoid(x)"
      ],
      "id": "IElDL0WPuyK9",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43WheJVzxAIY"
      },
      "source": [
        "### Training"
      ],
      "id": "43WheJVzxAIY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd1kfrd1UPXT"
      },
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    labels = torch.unsqueeze(d[\"label\"], 1)\n",
        "    labels = labels.float()\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=args['max_grad_norm'])\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return np.mean(losses)"
      ],
      "id": "Pd1kfrd1UPXT",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B8ctTAsUxsG"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = torch.unsqueeze(d[\"label\"], 1)\n",
        "      labels = labels.float()\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      losses.append(loss.item())\n",
        "  return np.mean(losses)"
      ],
      "id": "8B8ctTAsUxsG",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5cMbbkxxG9M"
      },
      "source": [
        "# Function to calculate predictions on test set\n",
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  predictions = []\n",
        "  real_values = []\n",
        "  originals = []\n",
        "  translations = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      ori = d[\"original_text\"]\n",
        "      trans = d[\"translation_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = torch.unsqueeze(d[\"label\"], 1)\n",
        "      labels = labels.float()\n",
        "      labels = labels.to(device)\n",
        "      preds = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      originals.extend(ori)\n",
        "      translations.extend(trans)\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return originals, translations, predictions, real_values"
      ],
      "id": "w5cMbbkxxG9M",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXGL_RZDTZez"
      },
      "source": [
        "### Hyperparameter Search"
      ],
      "id": "hXGL_RZDTZez"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oUhAsmvTp-g"
      },
      "source": [
        "lr_list = [1e-5]\n",
        "do_list = [0.1, 0.3, 0.5]"
      ],
      "id": "4oUhAsmvTp-g",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCMrBum_SIwN",
        "outputId": "0aa2456e-5644-4c98-c25b-66442bc5a105"
      },
      "source": [
        "for lr in lr_list:\n",
        "  for dropout in do_list:\n",
        "\n",
        "    # Initialize \n",
        "    print('Testing lr = {} and dropout = {}'.format(lr, dropout))\n",
        "    print('=========================================')\n",
        "    config = config_class.from_pretrained(MODEL_NAME, num_labels=1, \n",
        "                                          hidden_dropout_prob=dropout)\n",
        "    filename = 'en-de_lr'+str(lr)+'_d'+str(dropout)+'.txt'\n",
        "    output_path = os.path.join(OUTPUT_DIR, filename)\n",
        "\n",
        "\n",
        "    # Intialize model\n",
        "    model = MonoTransQuest(config)\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    # Set up optimizer and loss function\n",
        "    t_total = len(train_data_loader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
        "    warmup_steps = math.ceil(t_total * args['warmup_ratio'])\n",
        "    args['warmup_steps'] = warmup_steps if args['warmup_steps'] == 0 else args['warmup_steps']\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, eps=args['adam_epsilon'])\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer,\n",
        "      num_warmup_steps=args['warmup_steps'], \n",
        "      num_training_steps=t_total\n",
        "    )\n",
        "    loss_fn = nn.MSELoss().to(device)\n",
        "\n",
        "\n",
        "    # Train model\n",
        "    history = defaultdict(list)\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(args['num_train_epochs']):\n",
        "      print(f'Epoch {epoch + 1}/{args[\"num_train_epochs\"]}')\n",
        "      print('-' * 10)\n",
        "      train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        device,\n",
        "        scheduler,\n",
        "        len(df_train)\n",
        "      )\n",
        "      print(f'Train loss {train_loss}')\n",
        "      val_loss = eval_model(\n",
        "        model,\n",
        "        dev_data_loader,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        len(df_dev)\n",
        "      )\n",
        "      print(f'Val   loss {val_loss}')\n",
        "      print()\n",
        "      history['train_loss'].append(train_loss)\n",
        "      history['val_loss'].append(val_loss)\n",
        "      if val_loss < best_loss:\n",
        "        # torch.save(model.state_dict(), best_model_path)\n",
        "        best_loss = val_loss\n",
        "    \n",
        "    # Get predictions\n",
        "    originals, translations, predictions, real_values = get_predictions(model, test_data_loader)\n",
        "\n",
        "    preds = predictions.numpy().squeeze()\n",
        "    labels = real_values.numpy().squeeze()\n",
        "    original = np.array(originals)\n",
        "    translation = np.array(translations)\n",
        "\n",
        "    df_results = pd.DataFrame()\n",
        "    df_results['original'] = original\n",
        "    df_results['translation'] = translation\n",
        "    df_results['z_mean'] = labels\n",
        "    df_results['pred_zscore'] = preds\n",
        "\n",
        "    df_results = un_fit(df_results, 'pred_zscore')\n",
        "\n",
        "    get_metrics(df_results, output_path, dropout, lr)\n"
      ],
      "id": "XCMrBum_SIwN",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing lr = 1e-05 and dropout = 0.1\n",
            "=========================================\n",
            "Epoch 1/3\n",
            "----------\n",
            "Train loss 0.009263870282564313\n",
            "Val   loss 0.019425701711326838\n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train loss 0.007165302477128405\n",
            "Val   loss 0.016471236649900675\n",
            "\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train loss 0.0069490035193573154\n",
            "Val   loss 0.016208710983395578\n",
            "\n",
            "Pearson: 0.3060175456654193\n",
            "RMSE: 0.7651174699172246\n",
            "MAE: 0.6341998458682832\n",
            "Testing lr = 1e-05 and dropout = 0.3\n",
            "=========================================\n",
            "Epoch 1/3\n",
            "----------\n",
            "Train loss 0.011706476720848253\n",
            "Val   loss 0.016674597628414632\n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train loss 0.008233156250457146\n",
            "Val   loss 0.01490807158127427\n",
            "\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train loss 0.007915814729207861\n",
            "Val   loss 0.013859571242704987\n",
            "\n",
            "Pearson: 0.4053755160505979\n",
            "RMSE: 0.6827267391120234\n",
            "MAE: 0.5435138795086294\n",
            "Testing lr = 1e-05 and dropout = 0.5\n",
            "=========================================\n",
            "Epoch 1/3\n",
            "----------\n",
            "Train loss 0.013130266180328493\n",
            "Val   loss 0.015178360998630524\n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train loss 0.010551116633295481\n",
            "Val   loss 0.015051888227462768\n",
            "\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train loss 0.010433352770217294\n",
            "Val   loss 0.014992475468665362\n",
            "\n",
            "Pearson: 0.09763206962782414\n",
            "RMSE: 0.703256384969147\n",
            "MAE: 0.5603818918622496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Z170ExRkoBUg",
        "outputId": "e2f74cd7-b854-4ab2-9c64-6112cf3d5b45"
      },
      "source": [
        "df_results"
      ],
      "id": "Z170ExRkoBUg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>translation</th>\n",
              "      <th>z_mean</th>\n",
              "      <th>pred_zscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Sultan appoints judges, and can grant pard...</td>\n",
              "      <td>Der Sultan ernennt Richter und kann Begnadigun...</td>\n",
              "      <td>0.349371</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Antisemitism in modern Ukraine Antisemitism an...</td>\n",
              "      <td>Antisemitismus in der modernen Ukraine Antisem...</td>\n",
              "      <td>0.392435</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morales continued his feud with Buddy Rose, de...</td>\n",
              "      <td>Morales setzte seine Fehde mit Buddy Rose fort...</td>\n",
              "      <td>0.645034</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>American Maury Tripp attended the Jamboree fro...</td>\n",
              "      <td>Der Amerikaner Maury Tripp besuchte das Jambor...</td>\n",
              "      <td>0.544519</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He bowled a series of bouncers at Viv Richards...</td>\n",
              "      <td>Er boomte eine Reihe von Bouncern bei Viv Rich...</td>\n",
              "      <td>-0.589531</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Cleo chooses not to tell Joel straight away an...</td>\n",
              "      <td>Cleo entscheidet sich, Joel nicht sofort zu sa...</td>\n",
              "      <td>0.091082</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The circular forbid the passage of indigents a...</td>\n",
              "      <td>Das Rundschreiben verbietet den Durchgang von ...</td>\n",
              "      <td>0.733995</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The Dodgers, as the top seeded team in the Nat...</td>\n",
              "      <td>Die Dodgers, als Top-Team in der National Leag...</td>\n",
              "      <td>-0.343441</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>List of schools in Victoria Australian Army Ca...</td>\n",
              "      <td>Liste der Schulen in Victoria Australian Army ...</td>\n",
              "      <td>-0.559438</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Kleptoparasitism by skuas, particularly the gr...</td>\n",
              "      <td>Kleptoparasitismus durch skuas, besonders der ...</td>\n",
              "      <td>-0.382093</td>\n",
              "      <td>1.267143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              original  ... pred_zscore\n",
              "0    The Sultan appoints judges, and can grant pard...  ...    1.267143\n",
              "1    Antisemitism in modern Ukraine Antisemitism an...  ...    1.267143\n",
              "2    Morales continued his feud with Buddy Rose, de...  ...    1.267143\n",
              "3    American Maury Tripp attended the Jamboree fro...  ...    1.267143\n",
              "4    He bowled a series of bouncers at Viv Richards...  ...    1.267143\n",
              "..                                                 ...  ...         ...\n",
              "995  Cleo chooses not to tell Joel straight away an...  ...    1.267143\n",
              "996  The circular forbid the passage of indigents a...  ...    1.267143\n",
              "997  The Dodgers, as the top seeded team in the Nat...  ...    1.267143\n",
              "998  List of schools in Victoria Australian Army Ca...  ...    1.267143\n",
              "999  Kleptoparasitism by skuas, particularly the gr...  ...    1.267143\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDDhtQBjoCX1"
      },
      "source": [
        ""
      ],
      "id": "gDDhtQBjoCX1",
      "execution_count": null,
      "outputs": []
    }
  ]
}